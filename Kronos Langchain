# bash: pip install flask openai langchain pinecone-client

from flask import Flask, request, jsonify
import openai
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.memory import ConversationBufferMemory

app = Flask(__name__)

# Define AIâ€™s Role: Meta-AI that builds other AI Agents
meta_ai_prompt = """
You are an AI that creates LangChain-powered AI agents.
Your job is to:
1. Choose the best framework (LangChain, LlamaIndex, OpenAI API, etc.).
2. Generate full Python code for the AI Agent.
3. Ensure the generated AI can reason over multiple steps and use memory.
4. Suggest deployment options (AWS, GCP, local server).
"""

# Function to generate AI Agent code
def generate_langchain_ai(user_request):
    prompt = f"{meta_ai_prompt}\n\nUser Request: {user_request}"
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "system", "content": prompt}],
        temperature=0.7
    )

    return response["choices"][0]["message"]["content"]

# API Endpoint to Build LangChain AI Agents
@app.route('/build-langchain-agent', methods=['POST'])
def build_langchain_agent():
    try:
        data = request.get_json()
        user_request = data.get("query", "")

        if not user_request:
            return jsonify({"error": "Please provide a request."}), 400

        ai_agent_code = generate_langchain_ai(user_request)

        return jsonify({"ai_agent_code": ai_agent_code})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=5000, debug=True)
