# failure_prediction_bot.py

from flask import Flask, request, jsonify
import joblib
import numpy as np
import os

app = Flask(__name__)

# Load your pre-trained machine learning model
# Make sure 'failure_model.pkl' is in the same directory or provide a full path
MODEL_PATH = os.getenv("MODEL_PATH", "failure_model.pkl")
model = joblib.load(MODEL_PATH)

# Define the expected sensor features in order
EXPECTED_FEATURES = [
    "temperature",
    "pressure",
    "vibration",
    "voltage",
    "current",
    "depth",
    "salinity"
]

@app.route('/predict', methods=['POST'])
def predict():
    """
    Accepts JSON sensor input and returns a failure prediction.
    """
    data = request.json

    # Ensure all expected features are present
    try:
        input_vector = [float(data[feature]) for feature in EXPECTED_FEATURES]
    except KeyError as e:
        return jsonify({"error": f"Missing required sensor: {str(e)}"}), 400
    except ValueError:
        return jsonify({"error": "All sensor inputs must be numerical"}), 400

    try:
        # Reshape input for prediction
        prediction = model.predict([input_vector])[0]
        probability = model.predict_proba([input_vector])[0].tolist()

        return jsonify({
            "prediction": int(prediction),
            "probability": probability
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

# system_safety_agent.py

from flask import Flask, request, jsonify
from openai import OpenAI
import os

app = Flask(__name__)

# Initialize OpenAI client (ensure your OPENAI_API_KEY is set as an environment variable)
client = OpenAI()

# System Safety Agent Prompt Template
SYSTEM_SAFETY_PROMPT = """
You are a System Safety Engineering assistant specializing in underwater 
unmanned vehicles (UUVs). Your job is to help write documentation in compliance 
with MIL-STD-882E and other standards. Please format the response as structured text 
with bullet points or numbered sections where appropriate.
"""

@app.route('/generate', methods=['POST'])
def generate():
    """Handles POST requests with a user prompt and returns OpenAI response"""
    data = request.json
    user_prompt = data.get('prompt', '')

    if not user_prompt:
        return jsonify({'error': 'Prompt is required'}), 400

    try:
        # Compose the full prompt by adding system safety instructions
        full_prompt = SYSTEM_SAFETY_PROMPT + "\n\n" + user_prompt

        completion = client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": full_prompt}
            ]
        )

        response = completion.choices[0].message.content
        return jsonify({'response': response})

    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

